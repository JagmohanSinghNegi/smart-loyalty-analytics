"""Train loyalty models from RFM features and transaction history.

Functions:
- create_loyalty_labels(cleaned_csv, reference_date=None, label_window_days=60)
- train_and_evaluate(rfm_csv, cleaned_csv, output_model_path='models/loyalty_model.pkl')

When run as __main__, this script trains models using defaults (`models/rfm_features.csv` and `data/cleaned/sample_cleaned.csv`),
prints evaluation metrics, and saves the best model to `models/loyalty_model.pkl`.

Labeling logic:
- We choose a `reference_date` which acts as the cutoff for computing features.
- Labels are generated by checking whether a customer made any purchase in the period (reference_date, reference_date + label_window_days].
- If `reference_date` is None, we set it to `max(date) - label_window_days` so there is a forward window in the dataset to look for the label.
  This follows standard practice: compute features up to a cutoff and predict activity in the subsequent window.
"""
from typing import Optional, Dict, Any
import os
import pandas as pd
import numpy as np
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, roc_curve
import joblib


def create_loyalty_labels(cleaned_csv: str, reference_date: Optional[pd.Timestamp] = None, label_window_days: int = 60) -> pd.DataFrame:
    """Create loyalty labels for each customer.

    Args:
        cleaned_csv: Path to cleaned transactions CSV with columns ['transaction_id','customer_id','date','products','amount'].
        reference_date: Cutoff date for feature computation. Labels look for purchases after this date.
                        If None, set to `max(date) - label_window_days` so there is a forward window available.
        label_window_days: Number of days after `reference_date` to look for a repeat purchase.

    Returns:
        DataFrame with columns ['customer_id', 'label', 'reference_date'] where label is 1 if a purchase occurred
        in (reference_date, reference_date + label_window_days], else 0.
    """
    df = pd.read_csv(cleaned_csv, parse_dates=['date'], dayfirst=False)
    df['date'] = pd.to_datetime(df['date'], errors='coerce')

    if df['date'].isna().all():
        raise ValueError('All dates are invalid in cleaned CSV')

    max_date = df['date'].max()
    min_date = df['date'].min()
    
    if reference_date is None:
        # For small datasets, use median date or first date + some days
        total_days = (max_date - min_date).days
        if total_days > label_window_days:
            reference_date = max_date - pd.Timedelta(days=label_window_days)
        else:
            # For small date ranges, use midpoint
            reference_date = min_date + pd.Timedelta(days=total_days // 2)
    else:
        reference_date = pd.to_datetime(reference_date)

    window_start = reference_date
    window_end = reference_date + pd.Timedelta(days=label_window_days)

    # Customers present before/on reference_date
    customers_before = df[df['date'] <= reference_date]['customer_id'].unique()

    # For each such customer, check if they have any transaction in (reference_date, window_end]
    future_df = df[(df['date'] > reference_date) & (df['date'] <= window_end)]
    loyal_customers = set(future_df['customer_id'].unique())

    rows = []
    for cid in customers_before:
        label = 1 if cid in loyal_customers else 0
        rows.append({'customer_id': cid, 'label': label, 'reference_date': reference_date})

    labels_df = pd.DataFrame(rows)
    
    # Handle case where no labels are generated (all customers have no future transactions)
    if labels_df.empty:
        print(f"Warning: No customers found before reference date {reference_date}. Using alternative labeling...")
        # Alternative: label customers as loyal if they have 2+ transactions anywhere in dataset
        customer_counts = df['customer_id'].value_counts()
        rows = []
        for cid in df['customer_id'].unique():
            label = 1 if customer_counts[cid] >= 2 else 0
            rows.append({'customer_id': cid, 'label': label, 'reference_date': reference_date})
        labels_df = pd.DataFrame(rows)
    
    return labels_df


def train_and_evaluate(rfm_csv: str,
                       cleaned_csv: str,
                       output_model_path: str = 'models/loyalty_model.pkl',
                       random_state: int = 42) -> Dict[str, Any]:
    """Train Logistic Regression and Random Forest classifiers to predict loyalty.

    Args:
        rfm_csv: Path to RFM features CSV (expects columns: customer_id, recency, frequency, monetary, rfm_score).
        cleaned_csv: Path to cleaned transactions CSV used to create labels.
        output_model_path: Where to save the best model (joblib).

    Returns:
        Dictionary containing trained models, test data, and evaluation metrics.
    """
    rfm = pd.read_csv(rfm_csv)
    labels = create_loyalty_labels(cleaned_csv)

    # Merge features with labels
    data = pd.merge(rfm, labels[['customer_id', 'label']], on='customer_id', how='inner')
    data = data.dropna(subset=['label'])

    if data.empty:
        raise ValueError('No data available after merging RFM features and labels')

    X = data[['recency', 'frequency', 'monetary', 'rfm_score']]
    y = data['label'].astype(int)

    # For very small datasets, skip stratification or use different approach
    min_class_count = y.value_counts().min()
    if len(data) < 5 or min_class_count < 2:
        # For tiny datasets, use all data for training and eval on same data (not ideal but necessary)
        print(f"Small dataset detected (n={len(data)}, min_class={min_class_count}). Using all data for training.")
        X_train, X_test = X, X
        y_train, y_test = y, y
    else:
        # Train/test split with stratification
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state, stratify=y if y.nunique() > 1 else None)

    # Logistic Regression pipeline (scaling + LR)
    pipe_lr = Pipeline([
        ('scaler', StandardScaler()),
        ('clf', LogisticRegression(max_iter=2000, random_state=random_state))
    ])

    pipe_lr.fit(X_train, y_train)
    y_pred_lr = pipe_lr.predict(X_test)
    y_proba_lr = pipe_lr.predict_proba(X_test)[:, 1]

    metrics_lr = {
        'accuracy': accuracy_score(y_test, y_pred_lr),
        'precision': precision_score(y_test, y_pred_lr, zero_division=0),
        'recall': recall_score(y_test, y_pred_lr, zero_division=0),
        'roc_auc': roc_auc_score(y_test, y_proba_lr) if len(np.unique(y_test)) > 1 else 0.5
    }

    # Random Forest (no scaling required, but keep pipeline wrapper for consistency)
    pipe_rf = Pipeline([
        ('clf', RandomForestClassifier(n_estimators=100, random_state=random_state))
    ])

    pipe_rf.fit(X_train, y_train)
    y_pred_rf = pipe_rf.predict(X_test)
    # For RF, use predict_proba if available
    if hasattr(pipe_rf, 'predict_proba'):
        y_proba_rf = pipe_rf.predict_proba(X_test)[:, 1]
    else:
        y_proba_rf = np.zeros_like(y_test, dtype=float)

    metrics_rf = {
        'accuracy': accuracy_score(y_test, y_pred_rf),
        'precision': precision_score(y_test, y_pred_rf, zero_division=0),
        'recall': recall_score(y_test, y_pred_rf, zero_division=0),
        'roc_auc': roc_auc_score(y_test, y_proba_rf) if len(np.unique(y_test)) > 1 else 0.5
    }

    # Choose best model by ROC AUC
    best_model = pipe_rf if metrics_rf['roc_auc'] >= metrics_lr['roc_auc'] else pipe_lr
    # Save best model
    out_dir = os.path.dirname(output_model_path)
    if out_dir and not os.path.exists(out_dir):
        os.makedirs(out_dir, exist_ok=True)
    joblib.dump(best_model, output_model_path)

    # Save feature importances for RF if available
    rf_feature_importances = None
    try:
        if hasattr(pipe_rf.named_steps['clf'], 'feature_importances_'):
            rf_feature_importances = dict(zip(X.columns.tolist(), pipe_rf.named_steps['clf'].feature_importances_.tolist()))
            fi_path = os.path.join('models', 'rf_feature_importances.csv')
            pd.DataFrame(list(rf_feature_importances.items()), columns=['feature', 'importance']).to_csv(fi_path, index=False)
    except Exception:
        pass

    results = {
        'models': {
            'logistic': pipe_lr,
            'random_forest': pipe_rf,
            'best_model': best_model
        },
        'metrics': {
            'logistic': metrics_lr,
            'random_forest': metrics_rf
        },
        'test': {
            'X_test': X_test,
            'y_test': y_test,
            'y_proba_lr': y_proba_lr,
            'y_proba_rf': y_proba_rf
        },
        'rf_feature_importances': rf_feature_importances,
        'model_path': output_model_path
    }

    return results


if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument('--rfm', default=os.path.join('models', 'rfm_features.csv'))
    parser.add_argument('--cleaned', default=os.path.join('data', 'cleaned', 'sample_cleaned.csv'))
    parser.add_argument('--out', default=os.path.join('models', 'loyalty_model.pkl'))
    args = parser.parse_args()

    print('Training loyalty models...')
    res = train_and_evaluate(args.rfm, args.cleaned, args.out)
    print('Metrics (Logistic):', res['metrics']['logistic'])
    print('Metrics (RandomForest):', res['metrics']['random_forest'])
    print('Best model saved to:', res['model_path'])
